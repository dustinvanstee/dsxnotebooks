{"nbformat_minor": 0, "nbformat": 4, "cells": [{"source": "### Import Benchmark Code\n(dont worry if you see Syntax Error message)", "cell_type": "markdown", "metadata": {}}, {"source": "%AddJar https://github.com/dustinvanstee/dv-spark-bench/raw/master/target/scala-2.10/dv-spark-bench-assembly-1.0.jar -f", "execution_count": 1, "outputs": [{"name": "stdout", "text": "Starting download from https://github.com/dustinvanstee/dv-spark-bench/raw/master/target/scala-2.10/dv-spark-bench-assembly-1.0.jar\nFinished download of dv-spark-bench-assembly-1.0.jar\n", "output_type": "stream"}], "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "### Linear Regression Notebook example", "cell_type": "markdown", "metadata": {}}, {"source": "import dv.sparkbench.LinearRegression._\n\n// Create a new benchmark object\nval bm = new linearRegressionBenchmark(sc)\n//bm.verbose = false  // verbose flag that controls output\nbm setRunLabel \"dsx-linreg\"\nbm.verbose = false\n\n// For LinReg, threshold is set so low, that the algorithm will run the number of iterations requested and then exit\n//                       ex       feat  eps part int numIters\nbm addRun linearSettings(100    , 1000,0.5,10,  0.0, 10)\nbm addRun linearSettings(100    , 1000,0.5,10,  0.0, 100)\nbm addRun linearSettings(1000   , 1000,0.5,10,  0.0, 10)\nbm addRun linearSettings(10000  , 1000,0.5,10,  0.0, 10)\nbm addRun linearSettings(100000 , 1000,0.5,10,  0.0, 10)\nbm addRun linearSettings(100000 , 1000,0.5,100, 0.0, 10)\n\nbm loop\nbm printResults\n", "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "## Terasort Benchmark Example", "cell_type": "markdown", "metadata": {}}, {"source": "#### Object Storage (Swift) Configuration - REQUIRED", "cell_type": "markdown", "metadata": {}}, {"source": "// Setup Credentials to Swift object storage\n// The quickest way to set this up is to add any random file to your environtment (the 1010 icon at upper right)\n// and then click insert to code.  This will create a variable called \n// creditials_1 that will hold everything you need to make a connection.\n// Cut and paste your info into the template below (I have removed some of my local info)\n// (dont worry about the file name, we will be creating synthetic data during the runs)\n\n// I have a helper utility in utils to connect to bluemix object storage\nimport dv.sparkbench.utils._\n\nvar credentials_1 = scala.collection.mutable.HashMap[String, String](\n  \"auth_url\"->\"https://identity.open.softlayer.com\",\n  \"project\"->\"object_storage_xxxxxx\",\n  \"project_id\"->\"xxxxxxxxx\",\n  \"region\"->\"dallas\",\n  \"user_id\"->\"xxxxxxx\",\n  \"domain_id\"->\"xxxxxxx\",\n  \"domain_name\"->\"xxxxxx\",\n  \"username\"->\"xxxxxx\",\n  \"password\"->\"\"\"xxxxxx\"\"\",\n  \"container\"->\"xxxxxxx\",\n  \"tenantId\"->\"undefined\"\n)\n\n// important, keep this line here ....\ncredentials_1(\"name\") = \"keystone\"\n\n// Connect to object storage\nfuncs.swiftConnection(sc, credentials_1)\n\n// Setup directory names for teragen and terasort\nval filebase = \"swift://\" + credentials_1(\"container\") +  \".\" + credentials_1(\"name\") + \"/\"\nval datadir = filebase + \"tgen\"\nval sortdir = filebase + \"tsort\"", "execution_count": 2, "outputs": [], "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "#### Run Teragen / Terasort", "cell_type": "markdown", "metadata": {}}, {"source": "//Terasort Notebook example\nimport dv.sparkbench.Terasort._\n\nval bm = new tgts(sc)\nbm setRunLabel \"dsx\"\nbm.verbose = true\n\n// Since you only have 5 GB of default storage in Object storage, I recommend only using a max row setting of \n// 10m with will generate 1GB of data...\n// rows value can be suffixed with k,m,g,t for different powers of 10\n//\n//                          rows    input        output        part\n//bm addRun teraSettings(\"5m\"   , datadir, sortdir, 3)\nbm addRun teraSettings(\"1m\"   , datadir, sortdir, 3)\nbm addRun teraSettings(\"1k\"   , datadir, sortdir, 10)\n\nbm loop\nbm printResults", "execution_count": 9, "outputs": [{"name": "stdout", "text": "Generating Data\nSorting Data\nClearing** Data\nData gen time : 123.499297077(s) //// Sort time : 247.289594973(s) //// Cleartime : 126.507469383(s)\n", "output_type": "stream"}], "cell_type": "code", "metadata": {"collapsed": false}}], "metadata": {"kernelspec": {"name": "scala", "language": "scala", "display_name": "Scala 2.10 with Spark 1.6"}, "language_info": {"name": "scala"}}}