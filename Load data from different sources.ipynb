{
    "nbformat_minor": 0, 
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "name": "python2", 
            "display_name": "Python 2 with Spark 1.6"
        }
    }, 
    "cells": [
        {
            "source": "# Load data into a notebook from different sources", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "Before you can start analyzing your data, you have to load the data from a data source. You can store your data in many different data sources. This reference notebook shows you how to load and integrate data in a notebook from the following data sources:\n-  Object Storage\n-  dashDB\n-  Cloudant\n\nThe notebook sample code shows you how to load data into a notebook by using Python and the PySpark stack. You can copy and paste these code snippets into the notebook you are developing. \n\nThis notebook runs on Python 2 with Spark 1.6.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "## Table of contents\n\n- [Load data from Object Storage](#osv3)\n  - [Load data by using Python](#osv3_python)\n  - [Load data by using PySpark](#osv3_pyspark)\n- [Load data from dashDB](#dashdb)\n  - [Load data by using PySpark](#dashdb_pyspark)\n- [Load data from a Cloudant database](#cloudant)\n  - [Load data by using Python](#cloudant_python)\n  - [Load data by using PySpark](#cloudant_pyspark)\n- [Summary](#summary)", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"osv3\"></a>\n## Load data from Object Storage\nIBM\u00ae Object Storage for Bluemix\u00ae provides provides you with access to a fully provisioned Swift Object Storage account to manage your data. Object Storage uses OpenStack Identity (Keystone) for authentication and can be accessed directly by using [OpenStack Object Storage (Swift) API v3](http://developer.openstack.org/api-ref-identity-v3.html#credentials-v3). \n\nWhen you load data for use in a notebook, the data file is listed on the `Data` pane in the notebook and is stored in the Object Storage instance associated with your project.\n\nClick the next code cell to set the focus on the cell. Now add the credentials to access the data file to this code cell by selecting the **Data** icon on the notebook action bar. Then, if the data file is a CSV file, click **Insert to code>Credentials** on the data file in the `Data` pane.  If the data file has another format, clicking **Insert to code** adds the credentials; there is no `Insert to code` list.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">Note: The Python dictionary with the credentials that is generated for you is given a generic name. Rename the dictionary variable to `credentials_osv3` and run the code cell to proceed.</div>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "<a id=\"osv3_python\"></a>\n### Load data by using Python\n\nRun the next cells to load the data from a file in Object Storage by using Python functions: ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 2, 
            "source": "import requests, StringIO, json\n\ndef get_file_content(credentials):\n    \"\"\"For given credentials, this functions returns a StringIO object containg the file content \n    from the associated Bluemix Object Storage V3.\"\"\"\n\n    url1 = ''.join([credentials['auth_url'], '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n            'password': credentials['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                if(e2['interface']=='public'and e2['region']==credentials['region']):\n                    url2 = ''.join([e2['url'],'/', credentials['container'], '/', credentials['filename']])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO.StringIO(resp2.content)", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": 3, 
            "source": "import pandas as pd\n\ndata_df = pd.read_csv(get_file_content(credentials_osv3))\ndata_df.head()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 3, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country or Area</th>\n      <th>1990</th>\n      <th>1995</th>\n      <th>1996</th>\n      <th>1997</th>\n      <th>1998</th>\n      <th>1999</th>\n      <th>2000</th>\n      <th>2001</th>\n      <th>2002</th>\n      <th>2003</th>\n      <th>2004</th>\n      <th>2005</th>\n      <th>2006</th>\n      <th>2007</th>\n      <th>2008</th>\n      <th>2009</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albania</td>\n      <td>28385.000000</td>\n      <td>40311.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>38284.000000</td>\n      <td>30683.000000</td>\n      <td>30491.000000</td>\n      <td>35883.000000</td>\n      <td>27893.000000</td>\n      <td>42787.000000</td>\n      <td>42840.000000</td>\n      <td>32380.000000</td>\n      <td>30964.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Algeria</td>\n      <td>76160.000000</td>\n      <td>90270.000000</td>\n      <td>53380.000000</td>\n      <td>74460.000000</td>\n      <td>66470.0</td>\n      <td>50150.000000</td>\n      <td>64430.000000</td>\n      <td>43840.000000</td>\n      <td>37317.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Andorra</td>\n      <td>539.947998</td>\n      <td>510.673004</td>\n      <td>560.340027</td>\n      <td>434.475006</td>\n      <td>254.0</td>\n      <td>450.151001</td>\n      <td>518.666016</td>\n      <td>456.626007</td>\n      <td>565.559021</td>\n      <td>566.583008</td>\n      <td>567.044006</td>\n      <td>530.278015</td>\n      <td>353.220001</td>\n      <td>306.630005</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Anguilla</td>\n      <td>93.099998</td>\n      <td>100.730003</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>68.190002</td>\n      <td>70.730003</td>\n      <td>68.190002</td>\n      <td>108.769997</td>\n      <td>84.250000</td>\n      <td>124.400002</td>\n      <td>99.550003</td>\n      <td>86.290001</td>\n      <td>96.889999</td>\n      <td>71.080002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antigua and Barbuda</td>\n      <td>300.299988</td>\n      <td>374.500000</td>\n      <td>323.299988</td>\n      <td>279.200012</td>\n      <td>384.5</td>\n      <td>426.799988</td>\n      <td>249.600006</td>\n      <td>238.000000</td>\n      <td>268.600006</td>\n      <td>253.899994</td>\n      <td>426.899994</td>\n      <td>371.000000</td>\n      <td>332.799988</td>\n      <td>293.600006</td>\n      <td>392.500000</td>\n      <td>276.899994</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "       Country or Area          1990          1995          1996  \\\n0              Albania  28385.000000  40311.000000      0.000000   \n1              Algeria  76160.000000  90270.000000  53380.000000   \n2              Andorra    539.947998    510.673004    560.340027   \n3             Anguilla     93.099998    100.730003      0.000000   \n4  Antigua and Barbuda    300.299988    374.500000    323.299988   \n\n           1997     1998          1999          2000          2001  \\\n0      0.000000      0.0  38284.000000  30683.000000  30491.000000   \n1  74460.000000  66470.0  50150.000000  64430.000000  43840.000000   \n2    434.475006    254.0    450.151001    518.666016    456.626007   \n3      0.000000      0.0      0.000000     68.190002     70.730003   \n4    279.200012    384.5    426.799988    249.600006    238.000000   \n\n           2002          2003          2004          2005          2006  \\\n0  35883.000000  27893.000000  42787.000000  42840.000000  32380.000000   \n1  37317.000000      0.000000      0.000000      0.000000      0.000000   \n2    565.559021    566.583008    567.044006    530.278015    353.220001   \n3     68.190002    108.769997     84.250000    124.400002     99.550003   \n4    268.600006    253.899994    426.899994    371.000000    332.799988   \n\n           2007           2008        2009  \n0  30964.000000       0.000000    0.000000  \n1      0.000000  100000.000000    0.000000  \n2    306.630005       0.000000    0.000000  \n3     86.290001      96.889999   71.080002  \n4    293.600006     392.500000  276.899994  "
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "Now your data is in a `pandas.DataFrame` and you can begin analyzing it. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"osv3_pyspark\"></a>\n### Load data by using PySpark\n\nBefore you can access data in the data file in Object Storage by using the [`SparkContext`](https://spark.apache.org/docs/1.6.0/api/python/pyspark.html#pyspark.SparkContext) object, you must set the Hadoop configuration by using the following configuration function:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 4, 
            "source": "def set_hadoop_config(credentials):\n    \"\"\"This function sets the Hadoop configuration with given credentials, \n    so it is possible to access data using SparkContext\"\"\"\n    \n    prefix = \"fs.swift.service.\" + credentials['name']\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + \".auth.url\", credentials['auth_url']+'/v3/auth/tokens')\n    hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n    hconf.set(prefix + \".tenant\", credentials['project_id'])\n    hconf.set(prefix + \".username\", credentials['user_id'])\n    hconf.set(prefix + \".password\", credentials['password'])\n    hconf.setInt(prefix + \".http.port\", 8080)\n    hconf.set(prefix + \".region\", credentials['region'])\n    hconf.setBoolean(prefix + \".public\", True)", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "Set the Hadoop configuration and give it a name, for example, `keystone`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 5, 
            "source": "# you can choose any name\ncredentials_osv3['name'] = 'keystone'\nset_hadoop_config(credentials_osv3)\n\ndata_rdd = sc.textFile(\"swift://\" + credentials_osv3['container'] + \".\" + credentials_osv3['name'] + \"/\" + credentials_osv3['filename'])\ndata_rdd.take(5)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 5, 
                    "data": {
                        "text/plain": "[u'Country or Area,1990,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009',\n u'Albania,28385.0,40311.0,0.0,0.0,0.0,38284.0,30683.0,30491.0,35883.0,27893.0,42787.0,42840.0,32380.0,30964.0,0.0,0.0',\n u'Algeria,76160.0,90270.0,53380.0,74460.0,66470.0,50150.0,64430.0,43840.0,37317.0,0.0,0.0,0.0,0.0,0.0,100000.0,0.0',\n u'Andorra,539.947998047,510.67300415,560.340026855,434.475006104,254.0,450.151000977,518.666015625,456.62600708,565.559020996,566.583007812,567.044006348,530.278015137,353.220001221,306.630004883,0.0,0.0',\n u'Anguilla,93.0999984741,100.730003357,0.0,0.0,0.0,0.0,68.1900024414,70.7300033569,68.1900024414,108.769996643,84.25,124.400001526,99.5500030518,86.2900009155,96.8899993896,71.0800018311']"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "Now your data is in a `pyspark.RDD` and you can begin analyzing it. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">Note: To access CSV files in Object Storage and load data to use in the notebook, you can use the code generation functions on the `Insert to code` list on each data file in the `Data` pane in the notebook. </div>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"dashdb\"></a>\n## Load data from dashDB\n\ndashDB is a data warehousing and analytics solution. Use dashDB to store relational data, including special data types such as geospatial data. You can leverage the in-memory database technology to use both columnar and row-based tables. \n\nIn this notebook, you must use a connection to an IBM dashdDB for Bluemix service instance. You can create data service connections on your project page. The dashDB instance name appears in the `Data` pane. \n\nClick the next code cell and use the `Insert to code` function below the dashDB instance name in the `Data` pane to add the dashDB credentials. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">Note: The Python dictionary with the dashDB credentials that is generated for you is given a generic name. Rename the dictionary variable to `credentials_dashDB` and run the code cell to proceed.</div>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "<a id=\"dashdb_pyspark\"></a>\n### Load data by using PySpark\n\nAdd the credentials of your dashDB instance that contains your data and run the next cell to load this data.\n\nThe code in the cell reads the credentials and loads the data from dashBD into a DataFrame data structure.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 7, 
            "source": "from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\nprops = {}\nprops['user'] = credentials_dashdb['username']\nprops['password'] = credentials_dashdb['password']\n\n# fill in table name\ntable = credentials_dashdb['username'] + \".\" + \"PRECIPITATION\"\n\ndata_df = sqlContext.read.jdbc(credentials_dashdb['jdbcurl'],table,properties=props)\ndata_df.printSchema()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- COUNTRY_OR_AREA: string (nullable = true)\n |-- 1990: decimal(31,11) (nullable = true)\n |-- 1995: decimal(31,11) (nullable = true)\n |-- 1996: decimal(31,11) (nullable = true)\n |-- 1997: decimal(31,11) (nullable = true)\n |-- 1998: decimal(31,12) (nullable = true)\n |-- 1999: decimal(31,11) (nullable = true)\n |-- 2000: decimal(31,10) (nullable = true)\n |-- 2001: decimal(31,12) (nullable = true)\n |-- 2002: decimal(31,11) (nullable = true)\n |-- 2003: decimal(31,12) (nullable = true)\n |-- 2004: decimal(31,12) (nullable = true)\n |-- 2005: decimal(31,11) (nullable = true)\n |-- 2006: decimal(31,11) (nullable = true)\n |-- 2007: decimal(31,12) (nullable = true)\n |-- 2008: decimal(31,11) (nullable = true)\n |-- 2009: decimal(31,11) (nullable = true)\n\n"
                }
            ]
        }, 
        {
            "execution_count": 8, 
            "source": "data_df.take(5)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 8, 
                    "data": {
                        "text/plain": "[Row(COUNTRY_OR_AREA=u'Albania', 1990=Decimal('28385.00000000000'), 1995=Decimal('40311.00000000000'), 1996=Decimal('0E-11'), 1997=Decimal('0E-11'), 1998=Decimal('0E-12'), 1999=Decimal('38284.00000000000'), 2000=Decimal('30683.0000000000'), 2001=Decimal('30491.000000000000'), 2002=Decimal('35883.00000000000'), 2003=Decimal('27893.000000000000'), 2004=Decimal('42787.000000000000'), 2005=Decimal('42840.00000000000'), 2006=Decimal('32380.00000000000'), 2007=Decimal('30964.000000000000'), 2008=Decimal('0E-11'), 2009=Decimal('0E-11')),\n Row(COUNTRY_OR_AREA=u'Algeria', 1990=Decimal('76160.00000000000'), 1995=Decimal('90270.00000000000'), 1996=Decimal('53380.00000000000'), 1997=Decimal('74460.00000000000'), 1998=Decimal('66470.000000000000'), 1999=Decimal('50150.00000000000'), 2000=Decimal('64430.0000000000'), 2001=Decimal('43840.000000000000'), 2002=Decimal('37317.00000000000'), 2003=Decimal('0E-12'), 2004=Decimal('0E-12'), 2005=Decimal('0E-11'), 2006=Decimal('0E-11'), 2007=Decimal('0E-12'), 2008=Decimal('100000.00000000000'), 2009=Decimal('0E-11')),\n Row(COUNTRY_OR_AREA=u'Andorra', 1990=Decimal('539.94799804700'), 1995=Decimal('510.67300415000'), 1996=Decimal('560.34002685500'), 1997=Decimal('434.47500610400'), 1998=Decimal('254.000000000000'), 1999=Decimal('450.15100097700'), 2000=Decimal('518.6660156250'), 2001=Decimal('456.626007080000'), 2002=Decimal('565.55902099600'), 2003=Decimal('566.583007812000'), 2004=Decimal('567.044006348000'), 2005=Decimal('530.27801513700'), 2006=Decimal('353.22000122100'), 2007=Decimal('306.630004883000'), 2008=Decimal('0E-11'), 2009=Decimal('0E-11')),\n Row(COUNTRY_OR_AREA=u'Anguilla', 1990=Decimal('93.09999847410'), 1995=Decimal('100.73000335700'), 1996=Decimal('0E-11'), 1997=Decimal('0E-11'), 1998=Decimal('0E-12'), 1999=Decimal('0E-11'), 2000=Decimal('68.1900024414'), 2001=Decimal('70.730003356900'), 2002=Decimal('68.19000244140'), 2003=Decimal('108.769996643000'), 2004=Decimal('84.250000000000'), 2005=Decimal('124.40000152600'), 2006=Decimal('99.55000305180'), 2007=Decimal('86.290000915500'), 2008=Decimal('96.88999938960'), 2009=Decimal('71.08000183110')),\n Row(COUNTRY_OR_AREA=u'Antigua and Barbuda', 1990=Decimal('300.29998779300'), 1995=Decimal('374.50000000000'), 1996=Decimal('323.29998779300'), 1997=Decimal('279.20001220700'), 1998=Decimal('384.500000000000'), 1999=Decimal('426.79998779300'), 2000=Decimal('249.6000061040'), 2001=Decimal('238.000000000000'), 2002=Decimal('268.60000610400'), 2003=Decimal('253.899993896000'), 2004=Decimal('426.899993896000'), 2005=Decimal('371.00000000000'), 2006=Decimal('332.79998779300'), 2007=Decimal('293.600006104000'), 2008=Decimal('392.50000000000'), 2009=Decimal('276.89999389600'))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "Now your data is in a `pyspark.sql.DataFrame` and you can analyze it. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"cloudant\"></a>\n## Load data from a Cloudant database\nCloudant is a NoSQL database as a service (DBaaS) built to scale globally, run nonstop, and handle a wide variety of data types like JSON, full-text, and geospatial. Cloudant NoSQL DB is an operational data store optimized to handle concurrent reads and  writes and to provide high availability and data durability.\n\nIn this notebook, you must have an IBM Cloudant NoSQL Database for Bluemix service instance and a connection to this data service instance. You can create data service connections on your project page. The Cloudant NoSQL DB instance name appears in the **Data Sources** pane. \n\nClick the next code cell and use the `Insert to code` function below the Cloudant NoSQL DB instance name in the **Data Sources** pane to add the Cloudant credentials.  ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">Note: The Python dictionary with the Cloudant credentials that is generated for you is given a generic name. Rename the dictionary variable to `credentials_cloudant` and run the code cell to proceed.</div>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "<a id=\"cloudant_python\"></a>\n### Load data by using Python\n\nBefore you begin loading data from a Cloudant NoSQL DB instance to your notebook, ensure that you are using the latest database version. Do not use Cloudant 0.5.10 or earlier. For more information see [the Python library for Cloudant and CouchDB](https://github.com/cloudant/python-cloudant).", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "Install the `cloudant` package:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 10, 
            "source": "!pip install --user cloudant", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Requirement already satisfied (use --upgrade to upgrade): cloudant in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s674-5888358c77e4ab-3e1941541687/.local/lib/python2.7/site-packages\r\nRequirement already satisfied (use --upgrade to upgrade): requests<3.0.0,>=2.7.0 in /usr/local/src/bluemix_jupyter_bundle.v4/notebook/lib/python2.7/site-packages (from cloudant)\r\n"
                }
            ]
        }, 
        {
            "execution_count": 11, 
            "source": "from cloudant.client import Cloudant\nfrom cloudant.result import Result\nimport pandas as pd, json\n\nclient = Cloudant(credentials_cloudant['username'], credentials_cloudant['password'], url=credentials_cloudant['url'])\nclient.connect()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "List all existing databases:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 12, 
            "source": "client.all_dbs()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 12, 
                    "data": {
                        "text/plain": "[u'test_db', u'weather_db']"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "execution_count": 13, 
            "source": "# fill in database name \ndb_name = 'test_db'\nmy_database = client[db_name]\nresult_collection = Result(my_database.all_docs, include_docs=True)\ndata_df = pd.DataFrame([item['doc'] for item in result_collection])\ndata_df.head()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 13, 
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>_rev</th>\n      <th>age</th>\n      <th>city</th>\n      <th>country</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001</td>\n      <td>3-27cca37f6a255b60524bfbe865542404</td>\n      <td>32</td>\n      <td>Chicago</td>\n      <td>USA</td>\n      <td>Peter Smith</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>002</td>\n      <td>4-cb90fa2f6171a233cde1145ae345424e</td>\n      <td>26</td>\n      <td>New York City</td>\n      <td>USA</td>\n      <td>Maria Sanchez</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>003</td>\n      <td>5-e7eeaf3db3bb9d618e91bc4614883b57</td>\n      <td>52</td>\n      <td>Ontario</td>\n      <td>Canada</td>\n      <td>Don Spears</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004</td>\n      <td>5-12789958a18573ebb767b03bfaf83f4c</td>\n      <td>25</td>\n      <td>Berlin</td>\n      <td>Germany</td>\n      <td>Martin Mueller</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>005</td>\n      <td>3-1515da6fa41d2642f10b5f9d75bd9ad2</td>\n      <td>37</td>\n      <td>Ontario</td>\n      <td>Canada</td>\n      <td>Julia Ma</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   _id                                _rev  age           city  country  \\\n0  001  3-27cca37f6a255b60524bfbe865542404   32        Chicago      USA   \n1  002  4-cb90fa2f6171a233cde1145ae345424e   26  New York City      USA   \n2  003  5-e7eeaf3db3bb9d618e91bc4614883b57   52        Ontario   Canada   \n3  004  5-12789958a18573ebb767b03bfaf83f4c   25         Berlin  Germany   \n4  005  3-1515da6fa41d2642f10b5f9d75bd9ad2   37        Ontario   Canada   \n\n             name  \n0     Peter Smith  \n1   Maria Sanchez  \n2      Don Spears  \n3  Martin Mueller  \n4        Julia Ma  "
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "Now your data is in a `pandas.DataFrame` and you can start analyzing it.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"cloudant_pyspark\"></a>\n### Load data by using PySpark\n\nAdd the credentials of your Cloudant NoSQL DB instance that contains your data and run the next cell to load this data.\n\nThe code in the cell reads the credentials and loads the data from Cloudant into a DataFrame data structure.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 14, 
            "source": "from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# fill in database name \ndb_name = \"test_db\"\ndata_df = sqlContext.read.format(\"com.cloudant.spark\")\\\n.option(\"cloudant.host\", credentials_cloudant['host'])\\\n.option(\"cloudant.username\", credentials_cloudant['username'])\\\n.option(\"cloudant.password\", credentials_cloudant['password'])\\\n.load(db_name)\n\ndata_df.printSchema()", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- _id: string (nullable = true)\n |-- _rev: string (nullable = true)\n |-- age: long (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- name: string (nullable = true)\n\n"
                }
            ]
        }, 
        {
            "execution_count": 15, 
            "source": "data_df.take(5)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 15, 
                    "data": {
                        "text/plain": "[Row(_id=u'001', _rev=u'3-27cca37f6a255b60524bfbe865542404', age=32, city=u'Chicago', country=u'USA', name=u'Peter Smith'),\n Row(_id=u'002', _rev=u'4-cb90fa2f6171a233cde1145ae345424e', age=26, city=u'New York City', country=u'USA', name=u'Maria Sanchez'),\n Row(_id=u'003', _rev=u'5-e7eeaf3db3bb9d618e91bc4614883b57', age=52, city=u'Ontario', country=u'Canada', name=u'Don Spears'),\n Row(_id=u'004', _rev=u'5-12789958a18573ebb767b03bfaf83f4c', age=25, city=u'Berlin', country=u'Germany', name=u'Martin Mueller'),\n Row(_id=u'005', _rev=u'3-1515da6fa41d2642f10b5f9d75bd9ad2', age=37, city=u'Ontario', country=u'Canada', name=u'Julia Ma')]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "Now your data in a `pyspark.sql.DataFrame` and you can start analyzing it.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary\n\nIn this notebook, you learned how to load data from object storage, dashDB, or Cloudant to a notebook.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### Author\nSven Hafeneger is a member of the Data Science Experience development team at IBM Analytics in Germany. He holds a M.Sc. in Bioinformatics and is passionate about data analysis, machine learning and the Python ecosystem for data science. ", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "Copyright \u00a9 IBM Corp. 2016, 2017. This notebook and its source code are released under the terms of the MIT License.", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }
    ], 
    "nbformat": 4
}